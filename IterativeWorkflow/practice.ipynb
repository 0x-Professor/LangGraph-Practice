{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49f8107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict, Literal, Annotated\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22925320",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", api_key=\"AIzaSyAG7aFAc0BT2Fjz2l93Q7xsniYtGbIDAjE\", temperature=0.5, max_tokens=90000)\n",
    "evaluator_llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", api_key=\"AIzaSyAG7aFAc0BT2Fjz2l93Q7xsniYtGbIDAjE\", temperature=0.1, max_tokens=90000)\n",
    "generator_llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", api_key=\"AIzaSyAG7aFAc0BT2Fjz2l93Q7xsniYtGbIDAjE\", temperature=1.0, max_tokens=90000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afbae8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetState(TypedDict):\n",
    "    topic: str\n",
    "    tweet: str\n",
    "    evaluation: Literal[\"approve\", \"need_improvement\"]\n",
    "    feedback: str\n",
    "    iteration: int\n",
    "    max_iteration: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "090bce3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetEvaluation(BaseModel):\n",
    "    evaluation: Literal[\"approve\", \"need_improvement\"] = Field(..., description=\"The evaluation of the tweet\")\n",
    "    feedback: str = Field(..., description=\"Feedback for improvement if needed\")\n",
    "    score: int = Field(..., description=\"Score of the tweet based on evaluation criteria\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7933485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tweet(state: TweetState):\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a creative AI that generates tweets based on a given topic.\"),\n",
    "        HumanMessage(content=f\"\"\"Generate a tweet about: {state['topic']}\n",
    "                     -This is version {state['iteration']} of the tweet.\n",
    "                     -The tweet should be concise and engaging.\n",
    "                     -The maximum length is 280 characters.\n",
    "                     -The tweet should be suitable for a general audience.\n",
    "                     -The tweet should not contain any sensitive or inappropriate content.\n",
    "                     -The tweet should not contain any hashtags or mentions.\n",
    "                     -The tweet should reflect the current iteration of the topic.\"\"\"),\n",
    "    ]\n",
    "    response = generator_llm.invoke(messages).content\n",
    "    state['tweet'] = response\n",
    "    return {'tweet': response, 'iteration': state['iteration'] + 1, 'max_iteration': state['max_iteration']}\n",
    "def evaluate_tweet(state: TweetState):\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are an AI that evaluates tweets based on clarity, engagement, and relevance.\"),\n",
    "        HumanMessage(content=f\"\"\"Evaluate the following tweet: {state['tweet']}\n",
    "                     -Is it clear and concise?\n",
    "                     -Does it engage the audience?\n",
    "                     -Is it relevant to the topic?\n",
    "                     -Provide feedback for improvement if needed.\n",
    "                     -Return 'approve' if the tweet is good, otherwise 'need_improvement'.\n",
    "                     -Current iteration: {state['iteration']}\n",
    "                     -Maximum iterations allowed: {state['max_iteration']}\"\"\"),\n",
    "    ]\n",
    "    response = evaluator_llm.invoke(messages).content\n",
    "    state['evaluation'] = response\n",
    "    return {'evaluation': response, 'feedback': \"Feedback provided\" if response == \"need_improvement\" else \"\", 'iteration': state['iteration']}\n",
    "\n",
    "def optimize_tweet(state: TweetState):\n",
    "    if state['evaluation'] == \"need_improvement\":\n",
    "        messages = [\n",
    "            SystemMessage(content=\"You are an AI that optimizes tweets based on feedback.\"),\n",
    "            HumanMessage(content=f\"\"\"Optimize the following tweet based on the feedback: {state['tweet']}\n",
    "                         -Feedback: {state['feedback']}\n",
    "                         -Make it more engaging and relevant.\n",
    "                         -Ensure it is concise and clear.\n",
    "                         -Return the optimized tweet.\"\"\"),\n",
    "        ]\n",
    "        response = optimizer_llm.invoke(messages).content\n",
    "        state['tweet'] = response\n",
    "        return {'tweet': response, 'iteration': state['iteration']}\n",
    "    else:\n",
    "        return {'tweet': state['tweet'], 'iteration': state['iteration']}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e2ef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(TweetState)\n",
    "graph.add_node('generate', generate_tweet)\n",
    "graph.add_node('evaluate', evaluate_tweet)\n",
    "graph.add_node('optimize', optimize_tweet)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
